---
title: "Data Analysis Project :"
author: "Juliette Faure"
output:
  html_document:
    includes:
    code_folding: "hide"
    toc: true
    toc_float: true
    number_sections: false
  # pdf_document: default
---

# Marketing analysis 

<br>

## **I - General introduction**
<br>
<br>
**Origin**
<br>
The present data has been created for marketing analysis purposes. It assembles various personal information about 2239 customers, such as their education level, income, age, marital status, number of children at home... 
<br>

It also shows their consuming habits (amount spent on wine, on sweets...) and the number of purchases made on discounted products.
<br>

There is very few context concerning this dataframe, since the source is unknown.
It is not clear when these informations were registered, but probably by 2014 since the date of customers' enrollment within the company doesn't go further than 2014. 
<br>

**Aim**
<br>
*To predict the customer's behavior (Number of purchases made with a discount) depending on the most significant personal attributes*


**Attributes**

+ People

ID: Customer's unique identifier
<br>
Year_Birth: Customer's birth year
<br>
Education: Customer's education level
<br>
Marital_Status: Customer's marital status
<br>
Income: Customer's yearly household income
<br>
Kidhome: Number of children in customer's household
<br>
Teenhome: Number of teenagers in customer's household
<br>
Dt_Customer: Date of customer's enrollment with the company
<br>
Recency: Number of days since customer's last purchase
<br>
Complain: 1 if customer complained in the last 2 years, 0 otherwise

+ Products 

MntWines: Amount spent on wine in last 2 years
<br>
MntFruits: Amount spent on fruits in last 2 years
<br>
MntMeatProducts: Amount spent on meat in last 2 years
<br>
MntFishProducts: Amount spent on fish in last 2 years
<br>
MntSweetProducts: Amount spent on sweets in last 2 years
<br>
MntGoldProds: Amount spent on gold in last 2 years

+ Promotions

NumDealsPurchases: Number of purchases made with a discount
<br>
AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise
<br>
AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise
<br>
AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise
<br>
AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise
<br>
AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise
<br>
Response: 1 if customer accepted the offer in the last campaign, 0 otherwise
<br>
NumStorePurchases: Number of purchases made directly in stores


```{r, warning=F, message=F}

if(!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}
suppressPackageStartupMessages(pacman::p_load(tidyverse, gtsummary, ggpubr, moments, here, sjPlot, parameters, effectsize, pander, psych))

knitr::opts_chunk$set( comment = NA)

path =  here("JULIETTE") 
#setwd(path)
data <- read.table("marketing_campaign.csv", header=T, sep="\t")
```

## **II - Data overview and cleaning {.tabset}**

### Structure
```{r}
str(data)
```

### Summary
```{r}
pander(summary(data))
```

### Densities
```{r, warning=F, message=F}
data %>% 
  keep(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") + 
  geom_histogram()
``` 


We are only interested in the total number of promotions accepted by the customers, since we don't have details about the nature of each promotion. 
```{r}
data$AcceptedCmpTotal <- data$AcceptedCmp1 + data$AcceptedCmp2 + data$AcceptedCmp3 + data$AcceptedCmp4 + data$AcceptedCmp5 + data$Response 
``` 

The dataframe contains many variables, some are superfluous for our analysis (web visits and purchases, cumplains, catalog purchases, Z_Revenus and Z_CostContact which we don't have information about)
```{r}
data$Complain <- data$NumWebVisitsMonth <- data$NumWebPurchases <- data$NumCatalogPurchases <- data$Z_Revenue <- data$Z_CostContact <- data$AcceptedCmp1 <- data$AcceptedCmp2 <- data$AcceptedCmp3 <- data$AcceptedCmp4 <- data$AcceptedCmp5 <- data$Response <- NULL
```

Marital status can be simplified in only a few levels, and transformed into a factor.
Since the "other" section represents less than 1% of the participants, it is not enough to model it as a factor.
<br>
We then transform some relevant variables into factors.
<br>
For Kidhome, we fused the answers "1" and "2" because there are only 2% of "2" which is not enough information to model it a one separate factor.


```{r}
data$Marital_Status <-  factor(data$Marital_Status, labels = c("Other", "Single", "Single", "Married", "Single", "Together", "Single", "Other"))
data$Marital_Status[data$Marital_Status=="Other"] <- NA; data$Marital_Status = droplevels(data$Marital_Status)
data$ID <- factor(data$ID) 
data$Education <- factor(data$Education) 
data$Teenhome <-  factor(data$Teenhome)
data$AcceptedCmpTotal <-  factor(data$AcceptedCmpTotal)
data$Kidhome <-  factor(data$Kidhome, labels = c("no", "yes", "yes"))
```
<br>
We want to calculate the age of the customers. If we proceed with : "2021 - data$Year_Birth", we would get their current age. It makes more sense to get their age at the moment the data was registered, so we proceed with 2014 minus dataYear_Birth, although here we are only assuming that it was indeed registered in 2014.

```{r}
data$age <- 2014 - data$Year_Birth 
plot(data$age)
``` 

We see 3 outliers who seems to be older than 110 years old. The corresponding birth years are 1893, 1900 and 1899. The first one could be corrected by 1993, the second one would be due to 2 typing errors which is improbable, and the third could be replaced by 1999 but it corresponds to someone who has a PhD education level, which is unlikely at age 15.
Since the dataset is very big, we can choose to delete these lines.

```{r}
# which(data$age>110)
data <- data[-c(193, 240, 340),]
```

Here we observe peculiar outliers for "Income".

```{r, warning=F, message=F}
ggplot(data, aes(NumStorePurchases, Income)) + geom_point(color="blue", alpha=0.3, position = position_jitter())
```

```{r, warning=F, message=F}
newdf = data %>%
  filter(!ID %in% c(9432, 5555, 4619, 5336, 1501, 1503, 8475, 4931, 11181) ) 
```

```{r, warning=F, message=F}
ggplot(newdf, aes(NumStorePurchases, Income)) + geom_point(color="blue", alpha=0.3, position = position_jitter())
```

We then plot all the variables again, and check again whether anything is abnormal.

```{r, warning=F, message=F}
newdf %>% 
  keep(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") + 
  geom_histogram()
```


## **III - Modelling**

The aim of this analysis is to be able to predict the number of store purchases as well as the number of kids at home, based on selected relevant attributes. 
<br>

### **A. Linear model**

### A.1. First model
<br>
The first model is  
m1 <- lm(data=newdf, NumStorePurchases ~ Kidhome*Income*Education*age)
```{r, out.width="50%", warning=F, message=F}
m1 <- lm(data=newdf, NumStorePurchases ~ Kidhome*Income*Education*age) 
```
<br>
### A.2. Model selection

Here, we use the stepAIC function to filter the variables to keep, by choosing the best AIC.
```{r}
ms <- MASS::stepAIC(m1, direction = "both", trace = FALSE) 
ms$anova
```


The final model chosen here is:  
finalm1 <- lm(data=newdf,NumStorePurchases ~ Kidhome + Income + Education + age + Kidhome:Income + Kidhome:Education + Income:Education + Kidhome:age + Income:age + Education:age + Kidhome:Income:Education + Income:Education:age)
<br>
```{r}
finalm1 <- lm(data=newdf,NumStorePurchases ~ Kidhome + Income + Education + age + Kidhome:Income + Kidhome:Education + Income:Education + Kidhome:age + Income:age + Education:age + Kidhome:Income:Education + Income:Education:age)
```

### **A.3. Statistical inference**

We use the eta_squared function to compute the effect sizes.
Indeed we are not only interested in whether some variables are significant to explain the number of store purchases ; we also want to know their magnitude, their weight in the prediction of the number of store purchases.

```{r}
parameters::model_parameters(anova(finalm1))
effectsize::eta_squared(car::Anova(finalm1, type = 2), ci = 0.9, alternative = "two") 
```
We can conclude that the most important predictors are, in order, Income and Kidhome. The variables and interactions that include 0 in the confidence interval have a "meaningless" effect size, but we can still keep them in the model.

### **A.4. Plots and summary estimates** {.tabset}

#### Plot estimates
<br>
We call the sjPlot function to plot all the estimates or to plot only one term at a time.

```{r, fig.show="hold", out.width="50%", fig.align = 'center'}
sjPlot::plot_model(finalm1) 
```

#### Plot marginal effects
We call the sjPlot function to plot all the estimates or to plot only one term at a time.
```{r, fig.show="hold", out.width="50%"}
sjPlot::plot_model(finalm1, type = "pred", terms = "Kidhome", show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = "Income", show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "Kidhome"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "Education"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "age"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("age", "Kidhome"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("age", "Income", "Education"), show.data  = T, jitter = 1) 
```
<br>
<br>
As we could easily assume, the number of store purchases increases along with the income. A more counter-intuitive finding is that it's lower for customers who have kids ; this could be due to the fact that this dataframe doesn't take into account the number of store purchases of the other parents. 
<br>
<br>
Looking at the interaction effects between education and income, we see that for the same income, customers who received basic education are clearly separated from the other customers by purchasing less.
<br>
<br>
For the interaction between income and age, an interesting pattern appears : for the lowest incomes, the number of store purchases decreases with age, while the tendency is reversed for the highest wages.
<br>
<br>
We also observe an interaction effect between having kids at home and age : the number of store purchases stays stable for those who don't have kids at home, while it decreases for those who do have kids at home, possibly because when the parents get older, kids leave the house.
<br>
<br>
Finally, over time, the augmentation of the number of store purchases proportional to the salary stays stable except for every education level except for those who received basic education.

#### Summary table of standardized estimates

sjPlot enables us to summarize all the standardized estimates in a numeric form.  
```{r}
sjPlot::tab_model(effectsize::standardize(finalm1), rm.terms = c("*Education.Q", "Education^4", "Income:Education.C", "Education.Q" , "Kidhomeyes:Education.Q", "Income:Education.Q", "Kidhomeyes:Income:Education.Q", "Education.C" ,              "Kidhomeyes:Education.C"  ,      "Income:Education.C"  ,"Kidhomeyes:Income:Education.C", "Education^4",  "Kidhomeyes:Education^4", "Income:Education^4" , "Kidhomeyes:Income:Education^4"), show.intercept = F)   #
```
<br>
We see that R^2 and adjusted R^2 are of 0,51, which means this model explains 50% of the variance. In conclusion, the model is not satisfying enough. 

### **B. Principal component analysis**


```{r}
clean_data <-data[rowSums(is.na(data))==0, ]
pm1<-prcomp(clean_data[,-c(1,3,4,6,7,8,18)],  scale=TRUE)
summary(pm1)
```
<br>
Looking at cumulative proportion, we need 8 principal components to reach 0,90 proportion of variance.
<br>
<br>
We also see that PC6 is non-significant.  
We delete PC6 from the model, and this new model m3 is not significantly different from m2. 
<br>
<br>
Therefore, we keep the simplest, which is m3. With summary(m3), we see that all PCs are significant. We keep the model m3. 
#should I add comments ?
```{r}
data2 <- cbind(clean_data, pm1$x)
m2 <- lm(data=data2, NumStorePurchases ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8)
summary(m2)
m3 <- update(m2, . ~ . - PC6)
anova(m3, m2)
summary(m3)
```

```{r, warning=F, message=F}
sjPlot::tab_pca(pm1, show.cronb = F, show.var = T, nmbr.fctr = 8)
```
comments

### C. Regression

<br>
Another useful variable to explore is KidHome. Can we model consumers' behavior based on whether they have children or not ?  
<br>  

+ glm1 : AcceptedCmpTotal is not significant.  
By performing an anova test, we see that glm1 and glm2 don't differ significantly, so we can keep the simplest which is glm2.  
AIC of glm2 is also slightly better, which comforts us into keeping glm2.  

+ glm 2 : The number of fisher scoring iterations is acceptable (6)
The residual deviance / degree of freedom ratio is 0,89 and dispersion parameter is 1. 


```{r, warning=F, message=F}
glm1 <- glm(Kidhome ~ Income + age + NumStorePurchases + MntSweetProducts + MntWines + AcceptedCmpTotal, family = binomial, data = newdf)
summary(glm1)
glm2 <-update(glm1, . ~ . - AcceptedCmpTotal)
summary(glm2)
anova(glm2, glm1, test="Chisq")  

sjPlot::plot_model(glm2, type = "pred", terms = c("age", "Income", "NumStorePurchases"), show.data  = T, jitter = 1) 
```


## **IV - Conclusions**

## **V - Annex**

## Checking the assumptions of the linear model
<br>
In order to consider NumStorePurchases as a response variables for a linear model, we first have to check normality. 
<br>

```{r, fig.show="hold", out.width="50%", fig.align="center", warning=F, message=F}
ggplot(data, aes(x = NumStorePurchases)) +
  geom_histogram(aes(y = ..density..),
                 colour = 1, fill = "white") +
  geom_density(adjust = 1) + labs(title = "Purchases",
 caption = paste("skewness =", round(moments::skewness(data$NumStorePurchases, na.rm = TRUE),2)))
```
<br>
The data is intrinsically skewed because there are no negative values possible. Skewness is quite high (0.7) but remains tolerable regarding the nature of the data. It has to be kept in mind while performing the model assumption checks.
<br>
```{r, out.width="50%", warning=F, message=F}
m1 <- lm(data=newdf, NumStorePurchases ~ Kidhome*Income*Education*age)
plot(m1, c(1:2,4), ask=F)
```
<br>  
<br>  

+ For the residuals VS fitted plot, the central line is close to 0 but is not very flat. There seems to be a pattern ?

+ Paying attention to the quantile-quantile plot, most of the points follow normality, although the upper extreme point tend to deviate from normality.

+ Looking at the Cook's distance graph, there is no value higher that 0,06 : we can conclude that there are no outliers influencing the model.


