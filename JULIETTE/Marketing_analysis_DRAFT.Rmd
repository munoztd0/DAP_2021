---
output:
  html_document: default
  pdf_document: default
  title             : "Prediction of clients' purchases for marketing purposes"
  author: 
  - name          : "Juliette Faure"
---
## I- General introduction

**Origin**
The present dataframe has been created for marketing analysis purposes. It assembles various personal information about 2239 customers, such as their education level, income, age, marital status, number of children at home... 
It also shows their consuming habits (amount spent on wine, on sweets...) and the number of purchases made on discounted products.

There is very few context concerning this dataframe, since the source is unknown.
It is not clear when these informations were registered, but probably by 2014 since the date of customers' enrollment within the company doesn't go further than 2014. 

**Aim**
To predict the customer's behavior (Number of purchases made with a discount) depending on the most significant personal attributes



**Attributes** 

 + *People*

ID: Customer's unique identifier
Year_Birth: Customer's birth year
Education: Customer's education level
Marital_Status: Customer's marital status
Income: Customer's yearly household income
Kidhome: Number of children in customer's household
Teenhome: Number of teenagers in customer's household
Dt_Customer: Date of customer's enrollment with the company
Recency: Number of days since customer's last purchase
Complain: 1 if customer complained in the last 2 years, 0 otherwise

  + *Products*

MntWines: Amount spent on wine in last 2 years
MntFruits: Amount spent on fruits in last 2 years
MntMeatProducts: Amount spent on meat in last 2 years
MntFishProducts: Amount spent on fish in last 2 years
MntSweetProducts: Amount spent on sweets in last 2 years
MntGoldProds: Amount spent on gold in last 2 years

  + *Promotions*

NumDealsPurchases: Number of purchases made with a discount
AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise
AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise
AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise
AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise
AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise
Response: 1 if customer accepted the offer in the last campaign, 0 otherwise
NumStorePurchases: Number of purchases made directly in stores


Before loading the dataset, we want to make sure we have all the necessary packages installed and loaded, and that the code can be run by anybody.
```{r setup, include = FALSE}
if(!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}
pacman::p_load(tidyverse, gtsummary, ggpubr, moments, here, sjPlot, parameters, effectsize)

path =  here("JULIETTE") 
setwd(path)
data <- read.table("marketing_campaign.csv", header=T, sep="\t")
```

\clearpage

## II - Data overview and clearing
```{r}
summary(data)
str(data)
data %>% 
  keep(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") + 
  geom_histogram()
``` 
We are only interested in the total number of promotions accepted by the customers, since we don't have details about the nature of each promotion. 
```{r}
data$AcceptedCmpTotal <- data$AcceptedCmp1 + data$AcceptedCmp2 + data$AcceptedCmp3 + data$AcceptedCmp4 + data$AcceptedCmp5 + data$Response 
``` 
The dataframe contains many variables, some are superfluous for our analysis (web visits and purchases, cumplains, catalog purchases, Z_Revenus and Z_CostContact which we don't have information about)
```{r}
data$Complain <- data$NumWebVisitsMonth <- data$NumWebPurchases <- data$NumCatalogPurchases <- data$Z_Revenue <- data$Z_CostContact <- data$AcceptedCmp1 <- data$AcceptedCmp2 <- data$AcceptedCmp3 <- data$AcceptedCmp4 <- data$AcceptedCmp5 <- data$Response <- NULL
```
We want to calculate the age of the customers. If we proceed with : "2021 - data$Year_Birth", we would get their current age. It makes more sense to get their age at the moment the data was registered, so we proceed with 2014 minus dataYear_Birth, although here we are only assuming that it was indeed registered in 2014.

```{r}
data$age <- 2014 - data$Year_Birth 
plot(data$age)
``` 
We see 3 outliers who seems to be older than 110 years old. The corresponding birth years are 1893, 1900 and 1899. The first one could be corrected by 1993, the second one would be due to 2 typing errors which is improbable, and the third could be replaced by 1999 but it corresponds to someone who has a PhD education level, which is unlikely at age 15.
Since the dataset is very big, we can choose to delete these lines.
```{r}
which(data$age>110)
data <- data[-c(193, 240, 340),]

```
Marital_Status can be simplified in only a few levels, and transformed into a factor.
Since the "other" section represents less than 1% of the participants, it is not enough to model it as a factor.
We then transform some relevant variables into factors.
```{r}
data$Marital_Status <-  factor(data$Marital_Status, labels = c("Other", "Single", "Single", "Married", "Single", "Together", "Single", "Other"))
data$Marital_Status[data$Marital_Status=="Other"] <- NA; data$Marital_Status = droplevels(data$Marital_Status)

data$Education <- factor(data$Education) 
data$Teenhome <-  factor(data$Teenhome)
data$AcceptedCmpTotal <-  factor(data$AcceptedCmpTotal)
data$Kidhome <-  factor(data$Kidhome, labels = c("no", "yes", "yes"))
```
For Kidhome, we fused the answers "1" and "2" because there are only 2% of "2" which is not enough information to model it a one separate factor.

We now want to plot all the variables again, and check again whether anything is abnormal.
```{r}
data %>% 
  keep(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") + 
  geom_histogram()
```

## III - Hypotheses 

Here we will be eyeballing the relationship between various variables, and determine those that seem the most relevant for further analysis.
```{r}

data %>% 
      filter(!is.na(Marital_Status)) %>% 

ggplot(aes(MntWines, Marital_Status)) + geom_boxplot(na.rm = TRUE)

ggplot(data, aes(Kidhome, MntSweetProducts))+ geom_boxplot(outlier.colour =  "red") +  geom_point(position = position_jitter()) 

ggplot(data, aes(x=Income, y=NumStorePurchases)) +
  geom_violin(trim=FALSE, fill='#A4A4A4', color="darkred")+
  theme_minimal()

ggplot(data, aes(x=MntWines, y=Marital_Status)) +
  geom_violin(trim=FALSE, fill='#A4A4A4', color="darkred")+
  geom_boxplot(width=0.05) + theme_minimal()

```
NumStorePurchases seems to be the most useful variable to analyse since marketing analysis might want to determine which profils buy the most in the store. In order to consider NumStorePurchases as a response variables for a linear model, we first have to check normality. Here, skewness appears to be 0,7 which is at an acceptable level.
```{r}
ggplot(data, aes(x = NumStorePurchases)) +
  geom_histogram(aes(y = ..density..),
                 colour = 1, fill = "white") +
  geom_density(adjust = 1) + labs(title = "Purchases",
 caption = paste("skewness =", round(moments::skewness(data$NumStorePurchases, na.rm = TRUE),2)))

ggplot(data, aes(x = sqrt(NumStorePurchases))) +
  geom_histogram(aes(y = ..density..),
                 colour = 1, fill = "white") +
  geom_density(adjust = 1) + labs(title = "Purchases",
 caption = paste("skewness =", round(moments::skewness(data$NumStorePurchases, na.rm = TRUE),2)))
```
## IV - Modelling

### A. LINEAR MODEL

### **A.1. Creating the model**
```{r}
m1 <- lm(data=data, NumStorePurchases ~ Kidhome*Income*Education*age) 
plot(m1, c(1:2,4), ask=F)
plot(Income ~NumStorePurchases, col="lightblue", pch=19, cex=2,data)
text(Income ~NumStorePurchases, labels=ID,data, cex=0.9, font=1)
```
### **A.2. Assessing outliers :** here we observe peculiar outliers for "Income". One income is equal to 666 666, and when income is higher than 150 000, people probably don't respond. We can safely remove these outliers.
```{r}
newdf = data %>%
  filter(!ID %in% c(9432, 5555, 4619, 5336, 1501, 1503, 8475, 4931, 11181) ) 

plot(Income ~NumStorePurchases, col="lightblue", pch=19, cex=2,data=newdf)
```
### **A.3. Reassessing without the outliers**
```{r}
m1 <- lm(data=newdf, NumStorePurchases ~ Kidhome*Income*Education*age)
plot(m1, c(1:2,4), ask=F)
```
### **A.4. Filtering the variables to keep : AIC**
Here we use the stepAIC function to select the model that has the best AIC.
```{r}
ms <- MASS::stepAIC(m1, direction = "both", trace = FALSE) #il choisit le meilleur AIC
ms$anova
```
### **A.5. Computing the final model**
```{r}
finalm1 <- lm(data=newdf,NumStorePurchases ~ Kidhome + Income + Education + age + Kidhome:Income + Kidhome:Education + Income:Education + Kidhome:age + Income:age + Education:age + Kidhome:Income:Education + Income:Education:age)
```
### **A.6. Checking for interferences**
We first use the effectsize function : everything that has 0.00 on the left of the 90% CI column has a "meaningless" effect size, but we still keep them on the model.
We also call the sjPlot function to plot all the estimates or to plot only one term at a time.
```{r}
parameters::model_parameters(anova(finalm1))
effectsize::eta_squared(finalm1,ci = 0.9) 
sjPlot::plot_model(finalm1) 
sjPlot::plot_model(finalm1, type = "pred", terms = "Kidhome", show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = "Income", show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "Kidhome"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "Education"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("Income", "age"), show.data  = T, jitter = 1) 
sjPlot::plot_model(finalm1, type = "pred", terms = c("age", "Kidhome"), show.data  = T, jitter = 1) 
sjPlot::tab_model(finalm1, rm.terms = c("*Education.Q", "Education^4", "Income:Education.C", "Education.Q" , "Kidhomeyes:Education.Q", "Income:Education.Q", "Kidhomeyes:Income:Education.Q", "Education.C" ,              "Kidhomeyes:Education.C"  ,      "Income:Education.C"  ,"Kidhomeyes:Income:Education.C", "Education^4",  "Kidhomeyes:Education^4", "Income:Education^4" , "Kidhomeyes:Income:Education^4"))
```

### B. PRINCIPAL COMPONENT ANALYSIS


```{r}
clean_data <-data[rowSums(is.na(data))==0, ]
pm1<-prcomp(clean_data[,-c(1,3,4,6,7,8,18)],  scale=TRUE)
summary(pm1)

data2 <- cbind(clean_data, pm1$x)
m2 <- lm(data=data2, NumStorePurchases ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8)
summary(m2)
m3 <- update(m2, . ~ . - PC6)
anova(m3, m2)
summary(m3)
```
We need 8 principal components to reach 0,90.
We see that PC6 is non-significant.
We delete PC6 from the model, and this new model m3 is not significantly different from m2. Therefore we keep the simplest, which is m3. With summary(m3), we see that all PCs are significant. We keep the model m3.


