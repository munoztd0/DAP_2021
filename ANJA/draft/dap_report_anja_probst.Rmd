---
title             : "Early Biomarkers of Parkinson's Disease Based on Natural Connected Speech"
shorttitle        : "Biomarkers of Parkinson's Disease"

author: 
  - name          : "Anja Probst"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "24 rue du Général-Dufour, 1211 Genève 4"
    email         : "anja.probst@etu.unige.ch"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "University of Geneva"

authornote:

abstract: |
  Parkinson's Disease is a degenerative disorder of the nervous system that 
  globally affects more than 6 million people (doi:10.1016/S0140-6736(16)31678-6).
  While the most well-recognized symptoms of the disease are motor-related, such 
  as shaking and instability, a further group of symptoms, which is only partially motor-related
  and occurs in a majority of patients, are speech-altering symptoms (https://pubmed.ncbi.nlm.nih.gov/30223711/). 
  While the disease is well-recognizable at a later stage, it is exceptionally hard to diagnose 
  and differentiate in its early stages and appropriate treatment is often delayed. 
  In 2017, Hlavnička et al. have published a study suggesting that automated analysis of connected 
  speech can reveal early biomarkers in subjects with REM sleep behaviour disorder, who are at 
  high risk of developing Parkinson's disease. In this project I analyse the data set published by
  the authors that contains experimental evaluation of healthy controls (HC, $n=50$), subjects with REM
  sleep behaviour disorder (RBD, $n=50$), and subjects with Parkinson's Disease (PD, $n=30$). While the constraints
  of this project limit the scope of analysis, I will show that interesting insights into the data can be
  gained nontheless.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "doc"
output            : papaja::apa6_pdf
---
<!-- maybe changin the shorttitle to DAP porject or somehting alike but nice header btw -->
```{r setup, include = FALSE}
if (!require(pacman)) {
    install.packages(
        c("pacman", "remotes"),
        repos = "http://cran.us.r-project.org"
    )
}
if (!require(papaja)) {
    remotes::install_github("crsh/papaja")
}

pacman::p_load(
    tinylabels, apaTables, tidyverse, gtsummary, car, GGally,
    ggfortify, MASS, rcompanion, moments, utils, sjPlot, interactions,
    kableExtra, report, papaja, bookdown, vtable, captioner, reshape2,
    ggpubr, nnet, patchwork, stargazer, MuMIn, magick 
)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, comment = NA)
```

\clearpage

# Introduction

## Context of the Project

Patients with the neurodegenerative disease Parkinson's have numerous symptoms ranging from cognitive 
impairments to motor symptoms. Those symptoms may appear relatively late in the disease when the 
neurodegeneration has already widely spread in different areas of the brain (mainly Basal Ganglia). 
Main symptoms of PD are motor dysfunctions including abnormalities in the production and sound of 
speech of such patients (up to 90%). These abnormalities in speech and voice are called hypokinetic 
dysarthria which is characterized by a decreased quality of the speech, where the voice, sound formation 
as well as the articulation is impaired. As I mentioned before, often motor impairments are detected 
relatively late in the disease. To improve diagnostics and to detect the disease in a much earlier stage, 
the detection of biomarkers related to neurodegeneration could lead to a better prognosis and therapy of PD.

Therefore, the investigation of prodromal speech changes could be an appropriate and suitable approach. 
To investigate this approach, an automated speech monitoring system was developed, that uses a 
segmentation method for the precise estimation of voiced and unvoiced segments of speech, respirations, 
and pauses. Further proposed was a set of acoustic speech features based on the segmentation algorithm 
applicable to connected speech, allowing the description of complex vocal disturbances due to neurodegeneration 
including respiratory deficits, dysphonia, imprecise articulation, and dysrhythmia.

In this data analysis project, the main focus was to explore, if there are any speech patterns that 
support the usage of an automated speech monitoring system to detect prodromal parkinsonian 
neurodegeneration based on natural connected speech.

130 subjects were tested. 30 subjects with early, untreated Parkinson's disease (PD) where the disease 
is already manifested. 50 subjects with REM sleep behaviour disorder (RBD), which is a disease where 
its relatively likely to develop PD in a later phase. As a control group, 50 healthy subjects (HD) were included.

## Manual Variable Selection

Due to the constraints of this project, I reduced the data set from originally 62 variables to the best fitting 7. 
As I am looking specificially into the aspect of speech, and to evaluate if speech is a good predictor for PD, 
I chose speech related variables that were assessed empirically and were reported to have the most significant differences
between healthy controls and subjects with early stages of Parkinson's Disease.
Note that patient group will be extracted from the variable Participant_code. 
The resulting data set is summarized in Table\ \@ref(tab:summarize-data-frame)

```{R, prepare-data-set, echo = TRUE, results = FALSE}
cols.to.keep <- c(
    "Participant_code", "Age", "Gender", "Rate_of_speech_timing",
    "Rate_of_speech_timing.1", "Duration_of_pause_intervals",
    "Duration_of_pause_intervals.1"
)

# Above columns will be renamed to
rename.cols.to <- c(
    "Participant_code", "Age", "Gender", "Speech.Timing.Rate.Reading",
    "Speech.Timing.Rate.Monologue", "Pause.Interval.Duration.Reading",
    "Pause.Interval.Duration.Monologue"
)

csv.path <- "BiomarkersPD.csv"
df <- read.csv(csv.path, sep = ",", header = TRUE)

# Only keep required columns and rename them
df <- df[cols.to.keep]
colnames(df) <- rename.cols.to

# Replace "-" with NA
df[df == "-"] <- NA

# Get groups from participant codes by replacing numerical values
df$Group <- gsub("[[:digit:]]+", "", df$Participant_code)

# Participant codes no longer required, remove
df <- subset(df, select = -c(Participant_code))

# Convert columns to factors
col.names <- c("Group", "Gender")
df[col.names] <- lapply(df[col.names], as.factor)
```

## Data Description

For each sample in this data set ($n=130$), we have the following information:

- Demographic information:
  - Age (years)
  - Gender (M for male, F for female)

- Speech examination - Speaking task of reading passage: speakers read a standardized, phonetically-balanced text of 80 words twice
  - Duration_Of_Pause_Intervals_Reading: Duration of pause intervals (DPI) describes the quality of speech timing, as pauses can be heavily influenced by the ability to properly initiate speech, it is measured in miliseconds (ms)
  - Rate_Of_Speech_Timing_Reading: Rate of speech time (RST) includes voiced, unvoiced and pause intervals, it is measured in intervals per minute (-/min)

- Speech examination - Speaking task of monologue: participants were instructed to provide monologue about their interests, job, family or current activities for approximately 90 seconds
  - Duration_Of_Pause_Intervals_Monologue: Duration of pause intervals (DPI) describes the quality of speech timing, as pauses can be heavily influenced by the ability to properly initiate speech, it is measured in milliseconds (ms)
  - Rate_Of_Speech_Timing_Monologue: Rate of speech time (RST) includes voiced, unvoiced and pause intervals, it is measured in intervals per minute (-/min)

- Group: based on Participant Code
  - PD: subjects with Parkinson's disease
  - RBD: subjects with REM sleep behaviour disorder
  - HC: healthy controls

```{R summarize-data-frame, results = "asis"}
sumtable(df, out = "latex", anchor = "tab:summarize-data-frame", title = "Summary of the Data Set used in this Analysis")
```

```{R describe data frame variables, comment=NA}
str(df)
#frame overflow, not serious problem but not nice// check -> https://bookdown.org/yihui/rmarkdown-cookbook/text-width.html for hwo to fix it
```

\clearpage

# Data Pre-Processing
As an initial step, I created boxplots to check the distribution of the numerical data per group 
in detail (Figure \ref{fig:boxplots-and-correlations}).
At first glance, parts of the data show skewed distributions, as the mean (shown as a orange point)
differs substantially in many cases. This might prompt data transformations such as the $log$-transform.
Additionally, within each variable, the distributions between the groups were assessed for significant differences.
Here, the data showed significant differences between healthy controls (HC) and Parkinson's (PD) and REM sleep
behaviour disorder subjects (RBD), but no significant differences between PD and RBD. Based on this, I decided
to split the data anlysis part into two sections: (1) Creating a logistic regression model using `glm` to
discriminate between the two groups HC and PD and (2) creating a multinomial regression model which discriminates
between all three groups (HC, PD, and RBD).
```{R boxplots-and-correlations, fig.align = 'center', fig.cap = 'Distributions of data within variables and between groups. Some of the data shows skewed distributions (mean is represented by orange point), especially within the variable Age. While there is significant difference (t-Test) between healthy controls (HC) and subjects with Parkinson\'s disease (PD) as well as REM sleep behavior disorder (RBD), there are no significant differences between PD and RBD'}
df.melted <- melt(
    subset(df, select = -c(Gender)),
    id = "Group"
)

comparisons <- list(c("HC", "PD"), c("PD", "RBD"), c("HC", "RBD"))

ggplot(df.melted, aes(x = Group, y = value)) +
    geom_boxplot() +
    facet_wrap(~variable, ncol = 5, scales = "free") +
    labs(x = "Group", y = "value [ms, -/ms]", title = "Correlations of four main variables between groups") +
    stat_compare_means(
        method = "t.test",
        comparisons = comparisons,
        label = "p.signif"
    ) +
    stat_summary(
        fun = mean, geom = "point",
        shape = 16, size = 2.5,
        color = "orange", fill = "orange"
    ) +
    theme_light() +
    theme(
        strip.text.x = element_text(
            size = 7
        )
    )
# nice plots ! but.. we can't see the variable 
#try to shorten the names like so..
#labels <- c("Age" = "Age", "Speech.Timing.Rate.Reading" = "Reading", ....)
#facet_wrap(~variable, ncol = 5, scales = "free", labeller=labeller(variable = labels))
```

Based on the empirical variables chosen, I excpected them to correlate. Indeed, Figure \ref{fig:correlate-ggpairs-plot} shows
a relatively strong correlation between these variables. Based on visual inspection of the boxplots (Figure \ref{fig:boxplots-and-correlations}), I chose to remove outliers
in the following way: 
<!-- changed here to fit paginatiuon better -->

```{r correlate-ggpairs-plot, echo=FALSE, warning=FALSE, results='hide', fig.align = 'center', fig.cap = 'Plot based on ggpairs, colored by the response variable Group. The empirically collected speech data shows strong correlations (both positive and negative). In addition the density plots show the skewed distributions that were already seen in the boxplots.'}
ggpairs(
    df,
    aes(color = Group, alpha = 0.5),
    title = "Correlations between groups and variables",
    lower = list(combo = wrap("facethist", binwidth = 10.0)),
    upper = list(continuous = wrap("cor", size = 2))
) + theme_light(base_size = 7)
```

<!-- Based on visual inspection of the boxplots (Figure \ref{fig:boxplots-and-correlations}), I chose to remove outliers -->
<!-- in the following way:  put it above-->
```{r outlier-removal, echo=TRUE, results='hide'}
df <- df[df$Pause.Interval.Duration.Monologue < 600, ]
df <- df[(df$Group != "HC" | df$Pause.Interval.Duration.Monologue < 450), ]
```

Given a lack of correlation between age and any of the speech-related variables, I chose to not remove
outliers based on the variable age.

\clearpage

# Data Analysis

## Logistic Regression

As stated previously, I have seen that there are no significant differences between the groups PD and RBD.
Based on this observation, I will limit my initial investigation to creating a logistic regression model predicting 
between the groups HC and PD. Indeed, the paper from which the data was extracted explicitly
discusses the hard problem of differentiating PD from RBD, which might very well be impossible with 
generalised linear models. I will revisit this problem in the section Multinomial Regression.

As a first step, a subset is created that does not contain any observations from the group RBD.
```{r create subset without RBD, echo=TRUE, results='hide'}
df.binom <- data.frame(df[df$Group != "RBD", ])
```

Based on this subset, I first create simple logistic regression models with one response variable 
for each of the selected variables (Figure \ref{fig:simple-logistic-regression}). For simplicity
they were created using the `ggplot2` function `stat_smooth`. As can be seen by visual inspection 
of the data points (red), none of the predictors is sufficient to predict the response variable 
(Group) on its own, given the respective overlap between the two groups. 

```{r simple-logistic-regression, fig.align = 'center', fig.cap = 'Simple logistic regression models with one predictor each. For variables a to d, we can see a clear sigmoid curve, while variables e, and of course f, which is a factor, do not show such a curve.'}
p1 <- ggplot(df.binom, aes(x = Speech.Timing.Rate.Monologue, y = as.integer(Group) - 1)) +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Speech Timing Monologue (ms)", y = "Group", tag = "a") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p2 <- ggplot(df.binom, aes(x = Speech.Timing.Rate.Reading, y = as.integer(Group) - 1)) +
    xlab("Speech Timing Reading (ms)") +
    ylab("Group") +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Speech Timing Reading (ms)", y = "Group", tag = "b") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p3 <- ggplot(df.binom, aes(x = Pause.Interval.Duration.Reading, y = as.integer(Group) - 1)) +
    xlab("Pause Interval Reading (-/ms)") +
    ylab("Group") +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Pause Interval Reading (-/ms)", y = "Group", tag = "c") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p4 <- ggplot(df.binom, aes(x = Pause.Interval.Duration.Monologue, y = as.integer(Group) - 1)) +
    xlab("Pause Interval Monologue (-/ms)") +
    ylab("Group") +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Pause Interval Monologue (-/ms)", y = "Group", tag = "d") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p5 <- ggplot(df.binom, aes(x = Age, y = as.integer(Group) - 1)) +
    xlab("Age") +
    ylab("Group") +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Age", y = "Group", tag = "e") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p6 <- ggplot(df.binom, aes(x = as.integer(Gender), y = as.integer(Group) - 1)) +
    xlab("Gender") +
    ylab("Group") +
    geom_point(colour = "red", alpha = 0.5) +
    stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial)) +
    labs(x = "Gender", y = "Group", tag = "f") +
    theme_light() +
    theme(
        plot.tag = element_text(),
        axis.title = element_text(size = 7, face = "bold")
    )

p1 + p2 + p3 + p4 + p5 + p6
```

Given that a single predictor is clearly not sufficient, a series of multiple logistic regression models 
have to be built and evaluated. As I would have to test 64 models (all possible combinations plus 
intercept only) to be certain to have found the best one, I instead chose to use the automated model 
selection function `dredge` from the R package `MuMIn`. Starting from the global binomial model 
`Group ~ .` as an input, `dredge` enumerates all possible models and evaluates them based on their AIC.

```{R dredge-model-selection, echo = TRUE, results = FALSE}
m.full <- glm(
    data = df.binom, Group ~ .,
    family = binomial,
    na.action = "na.fail"
)

d <- dredge(m.full, rank = "AIC")

m.best.no.interactions <- get.models(d, 1)[[1]]
summary(m.best.no.interactions)
```
<!-- why dont you show the results ? either put them or put them in appendix, but I think a short sentence describing them is needed -->
<br> 

```{R table-best-model-dredge, echo=FALSE}
m.best.no.interactions.apa <- apa_print(m.best.no.interactions)
apa_table(
    m.best.no.interactions.apa$table,
    caption = "A full regression table of the best model (selected using dredge) without interactions."
)
```

Importantly, the above automated model selection did not consider interactions between the predictors.
Given the strong collinearity of the model (based the relatively strong correlation between the speech-related
variables) it would be interesting to see whether solely the interaction between two variables would provide
a better model. Indeed, the model below shows that solely focusing on the interactions provides a better result.

```{R interaction-model}
m.interactions <- glm(
    data = df.binom, Group ~ Pause.Interval.Duration.Reading:Pause.Interval.Duration.Monologue + Gender,
    family = binomial
)

m.interactions.apa <- apa_print(m.interactions)
apa_table(
    m.interactions.apa$table,
    caption = "A full regression table of a manually created model with based on an interaction between the variables Pause Interval Duration Reading and Pause Interval Duration Monologue."
)

# here the table goes berkserk too check first comment on wrapping text
```

<!-- good but not enough to show the table, now describe and interpret the results _. see the discussion on statistical inference on github + how good is the model, explained variance? effect size? -->

## PCA

<!-- why PCA?, what it does differnewlty briefly, and this section needs polishing-->
As there has been significant correlation between the predictors in the ggpairs plot
as well as some extreme changes in coefficients when adding additional variables,
there exists the possbility of collinearity negatively affecting the models. Indeed,
we observe variance inflation factors of more than 2.5 between all experimental predictors.
This warrants and attempt at solving the potential collinearity issue.

```{r vif, comment=NA}
vif(glm(data = df.binom, Group ~ ., family = binomial))
```

```{r run-pca, comment=NA}
# PCA
df.binom.pca <- prcomp(df.binom[, c(3, 4, 5, 6)], scale. = TRUE, center = TRUE)
summary(df.binom.pca)
```

Figure \ref{fig:pca-loadings} shows the loadings of the PCA. 

```{R pca-loadings, fig.align = 'center', fig.cap="PCA autoplot of PCs 1 and 2. It once again shows that there exists a strong correlation between the variables."}
# what else does it shows?
autoplot(
    df.binom.pca,
    data = df.binom,
    loadings = TRUE,
    loadings.label = TRUE,
    loadings.label.repel = TRUE,
    loadings.colour = "black",
    loadings.label.colour = "black",
    colour = "Group",
) +
    labs(title = "PCA of Speech Analysis Measurements") +
    theme_light()
```

Figure \ref{fig:pca-ggpairs} shows, that the PCA has resolved the correlations between the variables.

```{R pca-ggpairs, fig.cap = 'ggpairs plot where the speech-related variables have been replaced by the principal components of a PCA.'}
df.biom.pca.joined <- cbind(df.binom, df.binom.pca$x)
ggpairs(
    df.biom.pca.joined[, -c(3, 4, 5, 6)],
    aes(color = Group, alpha = 0.5),
    lower = list(combo = wrap("facethist", binwidth = 10.0)),
    upper = list(continuous = wrap("cor", size = 2))
) +
    theme_light(base_size = 7)
```

A comparison between the interaction model with a model based on PC1 and the variable gender, 
does not show a significant difference.

```{R, compare PCA-based model to best model from eval, comment=NA}
model.binom.pca <- glm(
    data = df.biom.pca.joined,
    Group ~ PC1 + Gender,
    family = "binomial"
)

# summary(model.binom.pca)
# autoplot(model.binom.pca, 1:6)

a <- anova(model.binom.pca, m.interactions, test = "Chisq")
print(a)
# ggplot(df.biom.pca.joined, aes(x = PC1, y = as.integer(Group) - 1)) +
#     geom_point() +
#     stat_smooth(method = "glm", se = TRUE, method.args = list(family = binomial))
```

## Multinomial Regression

To predict over all three groups (HC, PD, RBD), we have to use a more complex
multinomial model. In order to evaluate the multinomial model, I created a train and test set. The training set contains 70% of the observations, while the test set contains the
remaining 30%. 
Using the formula `Group ~ . - Age - Gender` results in the best performance.
<!-- do you shgow it somewhere in the papendix or >? -->

```{r multinomial-regression, echo=TRUE, comment=NA}
# Set reference level explicitly
df$Group <- relevel(df$Group, ref = "HC")

# Train / test split
set.seed(123)
sample <- sample.int(
    n = nrow(df), size = floor(0.7 * nrow(df)),
    replace = FALSE
)

df.train <- df[sample, ]
df.test <- df[-sample, ]

model.all <- multinom(
    Group ~ . - Age - Gender,
    data = df.train
)

df.train$Group.Predicted <- predict(
    model.all,
    newdata = df.train, "class"
)

tab <- table(df.train$Group, df.train$Group.Predicted)
tab
# nicer way ot output a confusion matrix
# calculate ratios instead of raw number to asses if True positive and false negative are high/low ? # check Lucile's DAP
accuracy <- round((sum(diag(tab)) / sum(tab)) * 100, 2)
```

The performance of this simple model is `r accuracy`%, this is especially interesting when inspecting the
confusion matrix above. None of the healthy subjects were diagnosed with Parkinson's disease, which is discrimination
important in a clinical setting. However, only 2 out of 17
<!-- ratios -->
subjects with PD were diagnosed correctly. In
addition, only 1 out of 35 subjects with RBD was misdiagnosed with PD.
<!-- what does all of that mean ? how could you chnage that ? hint: are the proportions of each categories the same ? -->

<!-- \clearpage not tneccesary here --> 

# Conclusion
Given the challenging nature of the data set, as well as the collinearity within it, the multinomial model
yielded surprisingly good performance by showing high specifity when diagnosing REM sleep behavior disorder
subjects and healthy controls. However, the logistic model, tasked with discriminating between 
healthy controls and subjects suffering from Parkinson's Disease, did not express satisfactory performance. Chosing
difference combinations of predictors only had a small influence on the outcome. While I attribute this to
the highly correlated predictors, a PCA-based model could not improve the situation and did not result in
significantly better performance.
<!-- ar eyou sure the correlation is the only thing to blame ? hint: are the proportions of each categories represneted equally? -->

\clearpage
<!-- i see the model selectio is here, good -->
```{R, include=FALSE, comment=NA}
# Appendix
## Manual Model Selection
model.binom.all.3 <- glm(
    data = df.binom,
    Group ~ Speech.Timing.Rate.Reading + Gender + Speech.Timing.Rate.Monologue,
    family = "binomial"
)

summary(model.binom.all.3)
# STRM not sign but AIC 94.9

model.binom.all.4 <- glm(
    data = df.binom,
    Group ~ Speech.Timing.Rate.Reading + Gender + Speech.Timing.Rate.Monologue + Pause.Interval.Duration.Reading,
    family = "binomial"
)

summary(model.binom.all.4)

model.binom.all.5 <- glm(
    data = df.binom,
    Group ~ Speech.Timing.Rate.Reading + Gender + Speech.Timing.Rate.Monologue + Pause.Interval.Duration.Reading + Pause.Interval.Duration.Monologue,
    family = "binomial"
)

summary(model.binom.all.5)

model.binom.all.6 <- glm(
    data = df.binom,
    Group ~ Speech.Timing.Rate.Monologue + Gender,
    family = "binomial"
)

summary(model.binom.all.6)

model.binom.all.7 <- glm(
    data = df.binom,
    Group ~ Pause.Interval.Duration.Monologue + Gender,
    family = "binomial"
)

summary(model.binom.all.7)

model.binom.all.8 <- glm(
    data = df.binom,
    Group ~ Pause.Interval.Duration.Reading + Gender,
    family = "binomial"
)

summary(model.binom.all.8)

model.binom.all.9 <- glm(
    data = df.binom,
    Group ~ Pause.Interval.Duration.Reading + Pause.Interval.Duration.Monologue + Gender,
    family = "binomial"
)

summary(model.binom.all.9)
# best model so far--> all sign. and AIC 88.3

model.binom.all.10 <- glm(
    data = df.binom,
    Group ~ Speech.Timing.Rate.Reading + Speech.Timing.Rate.Monologue + Gender,
    family = "binomial"
)

summary(model.binom.all.10)
```

## Manual Model Plot
<!-- put the model diagnostic plot and ocmment them birefly -->
```{R, include=FALSE}

# Move to appendix as example of how to do this "manually"
# df.binom <- data.frame(df[df$Group != "RBD",])

# model.binom.all <- glm(
#   Group ~ Speech.Timing.Rate.Monologue,
#   data=df.binom, family="binomial"
# )

# new.data <- data.frame(
#   Speech.Timing.Rate.Monologue=seq(
#     min(df.binom$Speech.Timing.Rate.Monologue),
#     max(df.binom$Speech.Timing.Rate.Monologue),
#     len=100
#   )
# )

# new.data$Group = predict(model.binom.all, new.data, type="response")

# ggplot(data=new.data, aes(x=Speech.Timing.Rate.Monologue, y=Group)) +
#   geom_line() +
#   geom_point(
#     data=df.binom, aes(x=Speech.Timing.Rate.Monologue, y=as.integer(Group)-1),
#     colour='red'
#   )
```

\clearpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

